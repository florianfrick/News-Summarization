{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Article Summarization with Encoder-Decoder Model\n",
    "\n",
    "Florian Frick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import BartTokenizer\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://medium.com/@bavalpreetsinghh/transformer-from-scratch-using-pytorch-28a5d1b2e033\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, emb_dim, max_seq_length):\n",
    "        super().__init__()\n",
    "        # Create fixed sinusoidal positional embeddings\n",
    "        pe = torch.zeros(max_seq_length, emb_dim)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / emb_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # even-index columns\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # odd-index columns\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.shape[1], :]  # Adjust to match the input size\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "  def __init__(self, emb_dim, head_size, causal=False):\n",
    "    super().__init__()\n",
    "    self.head_size = head_size\n",
    "\n",
    "    self.query = nn.Linear(emb_dim, head_size, bias=False)\n",
    "    self.key = nn.Linear(emb_dim, head_size, bias=False)\n",
    "    self.value = nn.Linear(emb_dim, head_size, bias=False)\n",
    "\n",
    "    self.causal = causal\n",
    "\n",
    "  def forward(self, x, kv=None, k_mask=None):\n",
    "    B, T, C = x.shape\n",
    "    Q = self.query(x)                            # Shape: (B, q_len, head_size)\n",
    "    K = self.key(kv if kv is not None else x)    # Shape: (B, seq_len, head_size) where seq_len = k_len if cross attention, else q_len\n",
    "    V = self.value(kv if kv is not None else x)  # Shape: (B, seq_len, head_size) where seq_len = k_len if cross attention, else q_len\n",
    "\n",
    "    # Dot Product of Queries and Keys\n",
    "    attention = Q @ K.transpose(-2,-1) # Shape: (B, q_len, k_len)\n",
    "\n",
    "    # Scaling to prevent softmax saturation\n",
    "    attention = attention / (self.head_size ** 0.5)\n",
    "    \n",
    "    # Applying k padding mask if provided (column-wise mask)\n",
    "    if k_mask is not None:\n",
    "      k_mask = k_mask.unsqueeze(1) # Shape: (B, 1, k_len) can be broadcast with attention\n",
    "      attention = attention.masked_fill(k_mask == 0, float(\"-inf\"))\n",
    "\n",
    "    # Applying causal mask for decoder's masked MHA\n",
    "    if self.causal:\n",
    "      c_mask = torch.tril(torch.ones(T, T, device=x.device)) # is broadcastable with attention (B, T, T)\n",
    "      attention = attention.masked_fill(c_mask == 0, float(\"-inf\"))\n",
    "\n",
    "    attention = torch.softmax(attention, dim=-1)\n",
    "\n",
    "    # Weighted sum of values\n",
    "    output = attention @ V # Shape: (B, seq_len, head_size)  where seq_len = k_len if cross attention, else q_len\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self, emb_dim, n_heads, causal=False):\n",
    "    super().__init__()\n",
    "    \n",
    "    assert emb_dim % n_heads == 0, \"emb_dim must be divisible by n_heads\"\n",
    "    \n",
    "    self.head_size = emb_dim // n_heads\n",
    "\n",
    "    self.W_o = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "\n",
    "    self.causal = causal\n",
    "\n",
    "    self.heads = nn.ModuleList([AttentionHead(emb_dim, self.head_size, causal=self.causal) for _ in range(n_heads)])\n",
    "\n",
    "  def forward(self, x, kv=None, k_mask=None):\n",
    "    # Combine attention heads\n",
    "    out = torch.cat([head(x, kv, k_mask=k_mask) for head in self.heads], dim=-1)\n",
    "    \n",
    "    out = self.W_o(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim, n_heads, r_mlp=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # Sub-Layer 1 Normalization\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "\n",
    "        # Multi-Head Attention\n",
    "        self.mha = MultiHeadAttention(emb_dim, n_heads)\n",
    "\n",
    "        # Dropout after MHA\n",
    "        self.dropout1 = nn.Dropout(dropout)  \n",
    "\n",
    "        # Sub-Layer 2 Normalization\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "\n",
    "        # Multilayer Perceptron\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.emb_dim, self.emb_dim * r_mlp),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.emb_dim * r_mlp, self.emb_dim)\n",
    "        )\n",
    "\n",
    "        # Dropout after MLP\n",
    "        self.dropout2 = nn.Dropout(dropout)  \n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        # Residual Connection After Sub-Layer 1 (MHA)\n",
    "        x = x + self.dropout1(self.mha(self.ln1(x), k_mask=src_mask))\n",
    "\n",
    "        # Residual Connection After Sub-Layer 2 (MLP)\n",
    "        x = x + self.dropout2(self.mlp(self.ln2(x)))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, emb_dim, n_heads, r_mlp=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.masked_mha = MultiHeadAttention(emb_dim, n_heads, causal=True)\n",
    "        self.dropout1 = nn.Dropout(dropout)  # Dropout after masked MHA\n",
    "\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "        self.cross_attention = MultiHeadAttention(emb_dim, n_heads)\n",
    "        self.dropout2 = nn.Dropout(dropout)  # Dropout after cross-attention\n",
    "\n",
    "        self.ln3 = nn.LayerNorm(emb_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.emb_dim, self.emb_dim * r_mlp),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.emb_dim * r_mlp, self.emb_dim)\n",
    "        )\n",
    "        self.dropout3 = nn.Dropout(dropout)  # Dropout after MLP\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n",
    "        x = x + self.dropout1(self.masked_mha(self.ln1(x), k_mask=tgt_mask))\n",
    "        x = x + self.dropout2(self.cross_attention(self.ln2(x), kv=encoder_output, k_mask=src_mask))\n",
    "        x = x + self.dropout3(self.mlp(self.ln3(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, max_seq_length, n_heads, n_layers, dropout=0.1):  \n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.positional_embedding = PositionalEmbedding(emb_dim, max_seq_length)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.encoder = nn.ModuleList(\n",
    "            [TransformerEncoder(emb_dim, n_heads, dropout=dropout) for _ in range(n_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, text, src_mask=None):\n",
    "        x = self.encoder_embedding(text)\n",
    "        x = self.positional_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for encoder_layer in self.encoder:\n",
    "            x = encoder_layer(x, src_mask=src_mask)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, max_seq_length, n_heads, n_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder_embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.positional_embedding = PositionalEmbedding(emb_dim, max_seq_length)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.decoder = nn.ModuleList(\n",
    "            [TransformerDecoder(emb_dim, n_heads, dropout=dropout) for _ in range(n_layers)]\n",
    "        )\n",
    "\n",
    "        self.output_projection = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "    def forward(self, tgt, encoder_outputs, src_mask=None, tgt_mask=None):\n",
    "        q = self.decoder_embedding(tgt)\n",
    "        q = self.positional_embedding(q)\n",
    "        q = self.dropout(q)  # Dropout after embedding\n",
    "\n",
    "        for decoder_layer in self.decoder:\n",
    "            q = decoder_layer(q, encoder_outputs, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "\n",
    "        q = self.output_projection(q)\n",
    "        return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, max_text_length, max_summary_length, n_heads, n_layers):\n",
    "        super().__init__()\n",
    "        self.encoder = TextEncoder(vocab_size, emb_dim, max_text_length, n_heads, n_layers)\n",
    "        self.decoder = TextDecoder(vocab_size, emb_dim, max_summary_length, n_heads, n_layers)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        encoder_outputs = self.encoder(src, src_mask=src_mask)\n",
    "        # print(tokenizer.tokenizer.batch_decode(tgt, skip_special_tokens=False))\n",
    "        decoder_outputs = self.decoder(tgt, encoder_outputs, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "        # print(\"Decoder Output:\", tokenizer.tokenizer.batch_decode(decoder_outputs.argmax(dim=-1), skip_special_tokens=False))\n",
    "        return decoder_outputs\n",
    "\n",
    "    def generate(self, src, src_mask=None, max_length=128):\n",
    "        encoder_outputs = self.encoder(src, src_mask=src_mask) # Shape: (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        B = src.size(0)\n",
    "        # Initialize predicted text with the start token {<s>: 0}\n",
    "        predicted_text = torch.full((B, 1), fill_value=0, device=src.device) # Shape: (B, 1)\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            decoder_outputs = self.decoder(predicted_text, encoder_outputs, src_mask=src_mask) # mask encoder outputs corresponding with padding in the input\n",
    "\n",
    "            # next_token = torch.multinomial(torch.softmax(decoder_outputs[:, -1, :], dim=-1), num_samples=1)  # Sample from the output distribution\n",
    "            next_token = decoder_outputs[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "\n",
    "            predicted_text = torch.cat((predicted_text, next_token), dim=1)\n",
    "\n",
    "            if torch.all(next_token == 2):  # Stop when all sequences predict <eos>\n",
    "                break\n",
    "                    \n",
    "        return predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bart Tokenizer:\n",
    "# tokenizer.tokenizer.decode([0,1,2])\n",
    "# '<s><pad></s>'\n",
    "class sumTokenizer:\n",
    "    def __init__(self, max_text_length=512, max_summary_length=128):\n",
    "        self.tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "        self.max_text_length = max_text_length\n",
    "        self.max_summary_length = max_summary_length\n",
    "        self.vocab_size = len(self.tokenizer)\n",
    "        \n",
    "    def __call__(self, text, is_target=False, padding=True, truncation=True):\n",
    "        if is_target:\n",
    "            return self.tokenizer(\n",
    "                text,\n",
    "                padding='max_length' if padding else False,\n",
    "                truncation=truncation,\n",
    "                max_length=self.max_summary_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "        else:\n",
    "            return self.tokenizer(\n",
    "                text,\n",
    "                padding='max_length' if padding else False,\n",
    "                truncation=truncation,\n",
    "                max_length=self.max_text_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "    \n",
    "    def decode(self, token_ids, skip_special_tokens=True):\n",
    "        return self.tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class xsumDataset(Dataset):\n",
    "    def __init__(self, split=\"train\", max_text_length=512, max_summary_length=128):\n",
    "        self.dataset = load_dataset(\"EdinburghNLP/xsum\")[split]\n",
    "        self.tokenizer = sumTokenizer(max_text_length, max_summary_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Get text and summary from dataset\n",
    "        text = self.dataset[i][\"document\"]\n",
    "        summary = self.dataset[i][\"summary\"]\n",
    "\n",
    "        # Tokenize input and target\n",
    "        inputs = self.tokenizer(text, is_target=False)\n",
    "        targets = self.tokenizer(summary, is_target=True)\n",
    "\n",
    "        target_ids = targets[\"input_ids\"].squeeze(0)\n",
    "\n",
    "        # Shift targets right for decoder input\n",
    "        decoder_input_ids = torch.cat(\n",
    "            [torch.tensor([1], device=target_ids.device), target_ids[:-1]]  # 1 is the <pad> token\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"input_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"target_ids\": target_ids,  # Used for loss calculation\n",
    "            \"decoder_input_ids\": decoder_input_ids,  # Shifted for decoder\n",
    "            \"target_mask\": targets[\"attention_mask\"].squeeze(0)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating that the encoder decoder can memorize a single training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDataset(Dataset):\n",
    "    def __init__(self, max_text_length=20, max_summary_length=10, total_examples=10, unk_text=False):\n",
    "        self.tokenizer = sumTokenizer(max_text_length, max_summary_length)\n",
    "\n",
    "        if unk_text:\n",
    "            self.text = \"A new text input unknown to the model.\"\n",
    "            self.summary = \"unknown input\"\n",
    "        else:\n",
    "            self.text = \"Example input to test whether model can memorize a single example\"\n",
    "            self.summary = \"The summary of example input\"\n",
    "        self.total_examples = total_examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_examples\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # Tokenize input and target\n",
    "        inputs = self.tokenizer(self.text, is_target=False)\n",
    "        targets = self.tokenizer(self.summary, is_target=True)\n",
    "\n",
    "        target_ids = targets[\"input_ids\"].squeeze(0)\n",
    "        \n",
    "        # Shift targets right: [<s>, The, summary, ..., </s>] -> [<pad>, <s>, The, summary, ...]\n",
    "        decoder_input_ids = torch.cat(\n",
    "            [torch.tensor([1], device=target_ids.device), target_ids[:-1]]  # Assuming 1 is the <pad> token\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"input_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"target_ids\": target_ids,  # Used for loss calculation\n",
    "            \"decoder_input_ids\": decoder_input_ids,  # Shifted for decoder\n",
    "            \"target_mask\": targets[\"attention_mask\"].squeeze(0)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda (NVIDIA GeForce RTX 4060)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "emb_dim = 256\n",
    "max_text_length=20\n",
    "max_summary_length=10\n",
    "text_heads = 8\n",
    "text_layers = 6\n",
    "\n",
    "epochs = 4\n",
    "batch_size = 2\n",
    "lr = 5e-5\n",
    "\n",
    "\n",
    "train_set = DummyDataset(max_text_length, max_summary_length)\n",
    "test_set = DummyDataset(max_text_length, max_summary_length, unk_text=True)\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Training loss: 11.298800468444824\n",
      "Training loss: 10.20062255859375\n",
      "Training loss: 9.440526962280273\n",
      "Training loss: 8.704160690307617\n",
      "Training loss: 7.706082820892334\n",
      "Epoch 2/4\n",
      "Training loss: 6.863729953765869\n",
      "Training loss: 6.277052879333496\n",
      "Training loss: 5.524877071380615\n",
      "Training loss: 4.868727684020996\n",
      "Training loss: 4.246597766876221\n",
      "Epoch 3/4\n",
      "Training loss: 3.675595998764038\n",
      "Training loss: 3.1386337280273438\n",
      "Training loss: 2.612342596054077\n",
      "Training loss: 1.9886587858200073\n",
      "Training loss: 1.601847529411316\n",
      "Epoch 4/4\n",
      "Training loss: 1.4121911525726318\n",
      "Training loss: 0.9618296027183533\n",
      "Training loss: 0.7298752069473267\n",
      "Training loss: 0.7371541261672974\n",
      "Training loss: 0.5315788984298706\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = sumTokenizer(max_text_length, max_summary_length)\n",
    "model = EncoderDecoder(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    emb_dim=emb_dim,\n",
    "    max_text_length=max_text_length,\n",
    "    max_summary_length=max_summary_length,\n",
    "    n_heads=text_heads,\n",
    "    n_layers=text_layers\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        src_mask = batch[\"input_mask\"].to(device)\n",
    "        target_ids = batch[\"target_ids\"].to(device)  # Unshifted, used for loss\n",
    "        decoder_input_ids = batch[\"decoder_input_ids\"].to(device)  # Shifted, used for input\n",
    "        tgt_mask = batch[\"target_mask\"].to(device)\n",
    "\n",
    "        # Forward pass with shifted decoder input\n",
    "        outputs = model(\n",
    "            input_ids,\n",
    "            decoder_input_ids,  # Use shifted target IDs\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask\n",
    "        )\n",
    "\n",
    "        # Compute loss (predicting `target_ids`)\n",
    "        loss = F.cross_entropy(\n",
    "            outputs.view(-1, outputs.size(-1)),  \n",
    "            target_ids.view(-1),                 \n",
    "            ignore_index=1  # Ensure 1 is actually the <pad> token!\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"Training loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input: <s>Example input to test whether model can memorize a single example</s><pad><pad><pad><pad><pad><pad>\n",
      "Test target: <s>The summary of example input</s><pad><pad><pad>\n",
      "forward: ['The summary of example input</s> of input input input', 'The summary of example input</s> of input input input']\n",
      "fwd ce loss: tensor(3.6662, device='cuda:0')\n",
      "Generated Output: ['<s>The summary of example input</s>', '<s>The summary of example input</s>']\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on a batch from the train loader (known dummy example)\n",
    "test_batch = next(iter(train_loader))\n",
    "input_ids = test_batch[\"input_ids\"].to(device)\n",
    "src_mask = test_batch[\"input_mask\"].to(device)\n",
    "target_ids = test_batch[\"target_ids\"].to(device)\n",
    "tgt_mask = test_batch[\"target_mask\"].to(device)\n",
    "\n",
    "print(\"Test input:\",tokenizer.tokenizer.decode(input_ids[0], skip_special_tokens=False))\n",
    "print(\"\\nTest target:\",tokenizer.tokenizer.decode(target_ids[0], skip_special_tokens=False))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids, src_mask=src_mask, max_length=max_summary_length)\n",
    "\n",
    "predicted_text = tokenizer.tokenizer.batch_decode(outputs, skip_special_tokens=False)  # Decode to text\n",
    "print(\"Generated Output:\", predicted_text)  # Print the predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input: <s>A new text input unknown to the model.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Test target: <s>unknown input</s><pad><pad><pad><pad><pad><pad>\n",
      "forward: ['The input</s> of input input input input input input', 'The input</s> of input input input input input input']\n",
      "fwd ce loss: tensor(6.1182, device='cuda:0')\n",
      "Predicted Output: ['The summary of example input', 'The summary of example input']\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on a batch from the test loader (unseen example)\n",
    "test_batch = next(iter(test_loader))\n",
    "input_ids = test_batch[\"input_ids\"].to(device)\n",
    "src_mask = test_batch[\"input_mask\"].to(device)\n",
    "target_ids = test_batch[\"target_ids\"].to(device)\n",
    "tgt_mask = test_batch[\"target_mask\"].to(device)\n",
    "\n",
    "print(\"Test input:\",tokenizer.tokenizer.decode(input_ids[0], skip_special_tokens=False))\n",
    "print(\"\\nTest target:\",tokenizer.tokenizer.decode(target_ids[0], skip_special_tokens=False))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids, src_mask=src_mask, max_length=max_summary_length)\n",
    "\n",
    "predicted_text = tokenizer.tokenizer.batch_decode(outputs, skip_special_tokens=True)  # Decode to text\n",
    "print(\"Predicted Output:\", predicted_text)  # Print the predicted output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on xsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "max_text_length=512\n",
    "max_summary_length=128\n",
    "text_heads = 8\n",
    "text_layers = 8\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 8\n",
    "lr = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = xsumDataset(split=\"train\", max_text_length=max_text_length, max_summary_length=max_summary_length)\n",
    "val_set = xsumDataset(split=\"validation\", max_text_length=max_text_length, max_summary_length=max_summary_length)\n",
    "test_set = xsumDataset(split=\"test\", max_text_length=max_text_length, max_summary_length=max_summary_length)\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, shuffle=False, batch_size=batch_size, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda (NVIDIA GeForce RTX 4060)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = sumTokenizer(max_text_length=max_text_length, max_summary_length=max_summary_length)\n",
    "model = EncoderDecoder(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    emb_dim=emb_dim,\n",
    "    max_text_length=max_text_length,\n",
    "    max_summary_length=max_summary_length,\n",
    "    n_heads=text_heads,\n",
    "    n_layers=text_layers\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 25506/25506 [1:44:01<00:00,  4.09it/s, loss=4.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation loss = 4.419611174032228\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 25506/25506 [8:50:33<00:00,  1.25s/it, loss=4.03]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation loss = 3.991926705744709\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 25506/25506 [1:42:47<00:00,  4.14it/s, loss=3.72]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validation loss = 3.742782992212892\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:   9%|▉         | 2293/25506 [08:36<1:27:12,  4.44it/s, loss=3.73]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m loss_history\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Backward pass with scaler for FP16 training\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m     41\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_history = []\n",
    "\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    model.train()  # Ensure model is in training mode\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        src_mask = batch[\"input_mask\"].to(device)\n",
    "        target_ids = batch[\"target_ids\"].to(device)  # Unshifted, used for loss\n",
    "        decoder_input_ids = batch[\"decoder_input_ids\"].to(device)  # Shifted, used for input\n",
    "        tgt_mask = batch[\"target_mask\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed precision forward pass with shifted decoder input\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            outputs = model(\n",
    "                input_ids,\n",
    "                decoder_input_ids,  # Use shifted targets as decoder input\n",
    "                src_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "\n",
    "            # Calculate cross entropy loss (predicting `target_ids`)\n",
    "            loss = F.cross_entropy(\n",
    "                outputs.view(-1, outputs.size(-1)),  # [B*summary_len, vocab_size]\n",
    "                target_ids.view(-1),                 # [B*summary_len]\n",
    "                ignore_index=1                       # Ignore padding tokens\n",
    "            )\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        # Backward pass with scaler for FP16 training\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Every 50 batches, print average loss and save model\n",
    "        if (batch_idx + 1) % 50 == 0:\n",
    "            avg_loss = np.mean(loss_history[-50:])\n",
    "            progress_bar.set_postfix(loss=avg_loss)\n",
    "            np.save(\"loss_history.npy\", np.array(loss_history))\n",
    "            torch.save(model.state_dict(), \"xsum_model.pt\")\n",
    "\n",
    "    # End-of-epoch: Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            src_mask = batch[\"input_mask\"].to(device)\n",
    "            target_ids = batch[\"target_ids\"].to(device)\n",
    "            decoder_input_ids = batch[\"decoder_input_ids\"].to(device)\n",
    "            tgt_mask = batch[\"target_mask\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                src=input_ids,\n",
    "                tgt=decoder_input_ids,  # Use shifted targets as decoder input\n",
    "                src_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "\n",
    "            loss = F.cross_entropy(\n",
    "                outputs.view(-1, outputs.size(-1)),\n",
    "                target_ids.view(-1),\n",
    "                ignore_index=1\n",
    "            )\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    print(f\"Epoch {epoch + 1}: Validation loss = {avg_val_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florian Frick\\AppData\\Local\\Temp\\ipykernel_11032\\3272035933.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"xsum_model.pt\"))\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"xsum_model.pt\"))\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the loss history from the .npy file\n",
    "loss_history = np.load('loss_history.npy')\n",
    "\n",
    "# Plot the loss history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history, label='Training Loss')\n",
    "plt.title('Training Loss Over Batches')\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input:\n",
      " \"The Security Council,\n",
      "Recalling its resolution 1970 (2011) of 26 February 2011,\n",
      "Deploring the failure of the Libyan authorities to comply with resolution 1970 (2011),\n",
      "Expressing grave concern at the deteriorating situation, the escalation of violence, and the heavy civilian casualties,\n",
      "Reiterating the responsibility of the Libyan authorities to protect the Libyan population and reaffirming that parties to armed conflicts bear the primary responsibility to take all feasible steps to ensure the protection of civilians,\n",
      "Condemning the gross and systematic violation of human rights, including arbitrary detentions, enforced disappearances, torture and summary executions,\n",
      "Further condemning acts of violence and intimidation committed by the Libyan authorities against journalists, media professionals and associated personnel and urging these authorities to comply with their obligations under international humanitarian law as outlined in resolution 1738 (2006),\n",
      "Considering that the widespread and systematic attacks currently taking place in the Libyan Arab Jamahiriya against the civilian population may amount to crimes against humanity,\n",
      "Recalling paragraph 26 of resolution 1970 (2011) in which the Council expressed its readiness to consider taking additional appropriate measures, as necessary, to facilitate and support the return of humanitarian agencies and make available humanitarian and related assistance in the Libyan Arab Jamahiriya,\n",
      "Expressing its determination to ensure the protection of civilians and civilian populated areas and the rapid and unimpeded passage of humanitarian assistance and the safety of humanitarian personnel,\n",
      "Recalling the condemnation by the League of Arab States, the African Union and the Secretary-General of the Organization of the Islamic Conference of the serious violations of human rights and international humanitarian law that have been and are being committed in the Libyan Arab Jamahiriya,\n",
      "Taking note of the final communiqué of the Organization of the Islamic Conference of 8 March 2011, and the communiqué of the Peace and Security Council of the African Union of 10 March 2011 which established an ad hoc High-Level Committee on Libya,\n",
      "Taking note also of the decision of the Council of the League of Arab States of 12 March 2011 to call for the imposition of a no-fly zone on Libyan military aviation, and to establish safe areas in places exposed to shelling as a precautionary measure that allows the protection of the Libyan people and foreign nationals residing in the Libyan Arab Jamahiriya,\n",
      "Taking note further of the Secretary-General's call on 16 March 2011 for an immediate ceasefire,\n",
      "Recalling its decision to refer the situation in the Libyan Arab Jamahiriya since 15 February 2011 to the Prosecutor of the International Criminal\n",
      "\n",
      "Test target: Here is the full text of UN resolution 1973 imposing a no-fly zone and other sanctions on Libya.\n",
      "Generated Output: The government has been a \"violent\" of violence in the country's capital, Mogadishu, as a result of the government...................................................\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on a batch from the train loader (seen example)\n",
    "test_batch = next(iter(train_loader))\n",
    "input_ids = test_batch[\"input_ids\"].to(device)\n",
    "src_mask = test_batch[\"input_mask\"].to(device)\n",
    "target_ids = test_batch[\"target_ids\"].to(device)\n",
    "tgt_mask = test_batch[\"target_mask\"].to(device)\n",
    "\n",
    "print(\"Test input:\\n\",tokenizer.tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "print(\"\\nTest target:\",tokenizer.tokenizer.decode(target_ids[0], skip_special_tokens=True))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids, src_mask=src_mask, max_length=max_summary_length)\n",
    "\n",
    "predicted_text = tokenizer.tokenizer.batch_decode(outputs, skip_special_tokens=True)  # Decode to text\n",
    "print(\"Generated Output:\", predicted_text[0])  # Print the predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input:\n",
      " Prison Link Cymru had 1,099 referrals in 2015-16 and said some ex-offenders were living rough for up to a year before finding suitable accommodation.\n",
      "Workers at the charity claim investment in housing would be cheaper than jailing homeless repeat offenders.\n",
      "The Welsh Government said more people than ever were getting help to address housing problems.\n",
      "Changes to the Housing Act in Wales, introduced in 2015, removed the right for prison leavers to be given priority for accommodation.\n",
      "Prison Link Cymru, which helps people find accommodation after their release, said things were generally good for women because issues such as children or domestic violence were now considered.\n",
      "However, the same could not be said for men, the charity said, because issues which often affect them, such as post traumatic stress disorder or drug dependency, were often viewed as less of a priority.\n",
      "Andrew Stevens, who works in Welsh prisons trying to secure housing for prison leavers, said the need for accommodation was \"chronic\".\n",
      "\"There's a desperate need for it, finding suitable accommodation for those leaving prison there is just a lack of it everywhere,\" he said.\n",
      "\"It could take six months to a year, without a lot of help they could be on the streets for six months.\n",
      "\"When you think of the consequences of either being on the street, especially with the cold weather at the moment or you may have a roof over your head, sometimes there is only one choice.\"\n",
      "Mr Stevens believes building more one-bedroom flats could help ease the problem.\n",
      "\"The average price is a hundred pounds a week to keep someone in a rented flat, prison is a lot more than that so I would imagine it would save the public purse quite a few pounds,\" he said.\n",
      "Official figures show 830 one-bedroom properties were built in the year to March 2016, of an overall total of 6,900 new properties in Wales.\n",
      "Marc, 50, who has been in and out of prison for the past 20 years for burglary offences, said he struggled to find accommodation each time he was released.\n",
      "He said he would ask himself: \"Where am I going to stay? Where am I going to live? Have I got somewhere where I can see my daughter.\"\n",
      "\"You're put out among the same sort of people doing the same sort of thing, and it's difficult, it's difficult to get away from it. It's like every man for himself, there's nothing.\"\n",
      "Marc has now\n",
      "\n",
      "Test target: There is a \"chronic\" need for more housing for prison leavers in Wales, according to a charity.\n",
      "Predicted Output: Students at a prison in Wales have risen. to a year, according to new figures.......................................................\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on a batch from the test loader (unseen example)\n",
    "test_batch = next(iter(test_loader))\n",
    "input_ids = test_batch[\"input_ids\"].to(device)\n",
    "src_mask = test_batch[\"input_mask\"].to(device)\n",
    "target_ids = test_batch[\"target_ids\"].to(device)\n",
    "tgt_mask = test_batch[\"target_mask\"].to(device)\n",
    "\n",
    "print(\"Test input:\\n\",tokenizer.tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "print(\"\\nTest target:\",tokenizer.tokenizer.decode(target_ids[0], skip_special_tokens=True))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids, src_mask=src_mask, max_length=max_summary_length)\n",
    "\n",
    "predicted_text = tokenizer.tokenizer.batch_decode(outputs, skip_special_tokens=True)  # Decode to text\n",
    "print(\"Predicted Output:\", predicted_text[0])  # Print the predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 11.3033\n",
      "ROUGE-1 Score: 0.0842\n",
      "ROUGE-2 Score: 0.0264\n",
      "ROUGE-L Score: 0.0697\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Initialize the ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "test_loss = 0\n",
    "all_references = []\n",
    "all_hypotheses = []\n",
    "rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for batch in test_loader:\n",
    "        # Move everything to device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        src_mask = batch[\"input_mask\"].to(device)\n",
    "        target_ids = batch[\"target_ids\"].to(device)\n",
    "        tgt_mask = batch[\"target_mask\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids,\n",
    "            target_ids,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask\n",
    "        )\n",
    "\n",
    "        # Calculate cross entropy loss directly\n",
    "        loss = F.cross_entropy(\n",
    "            outputs.view(-1, outputs.size(-1)),\n",
    "            target_ids.view(-1),\n",
    "            ignore_index=1\n",
    "        )\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Convert outputs and targets to strings for ROUGE score\n",
    "        predictions = outputs.argmax(dim=-1).tolist()\n",
    "        references = target_ids.tolist()\n",
    "        \n",
    "        for pred, ref in zip(predictions, references):\n",
    "            pred_str = ' '.join(map(str, pred))\n",
    "            ref_str = ' '.join(map(str, ref))\n",
    "            \n",
    "            # Calculate ROUGE scores for each prediction and reference\n",
    "            score = scorer.score(ref_str, pred_str)\n",
    "            \n",
    "            rouge_scores['rouge1'].append(score['rouge1'])\n",
    "            rouge_scores['rouge2'].append(score['rouge2'])\n",
    "            rouge_scores['rougeL'].append(score['rougeL'])\n",
    "\n",
    "# Calculate average test loss\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "# Calculate average ROUGE scores\n",
    "avg_rouge1 = sum([score.fmeasure for score in rouge_scores['rouge1']]) / len(rouge_scores['rouge1'])\n",
    "avg_rouge2 = sum([score.fmeasure for score in rouge_scores['rouge2']]) / len(rouge_scores['rouge2'])\n",
    "avg_rougeL = sum([score.fmeasure for score in rouge_scores['rougeL']]) / len(rouge_scores['rougeL'])\n",
    "\n",
    "print(f\"ROUGE-1 Score: {avg_rouge1:.4f}\")\n",
    "print(f\"ROUGE-2 Score: {avg_rouge2:.4f}\")\n",
    "print(f\"ROUGE-L Score: {avg_rougeL:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 53374809\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
