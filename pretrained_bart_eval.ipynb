{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Pretrained Bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-xsum\").to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 406290432\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sumTokenizer:\n",
    "    def __init__(self, max_text_length=512, max_summary_length=128):\n",
    "        self.tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-xsum')\n",
    "        self.max_text_length = max_text_length\n",
    "        self.max_summary_length = max_summary_length\n",
    "        self.vocab_size = len(self.tokenizer)\n",
    "        \n",
    "    def __call__(self, text, is_target=False, padding=True, truncation=True):\n",
    "        if is_target:\n",
    "            return self.tokenizer(\n",
    "                text,\n",
    "                padding='max_length' if padding else False,\n",
    "                truncation=truncation,\n",
    "                max_length=self.max_summary_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "        else:\n",
    "            return self.tokenizer(\n",
    "                text,\n",
    "                padding='max_length' if padding else False,\n",
    "                truncation=truncation,\n",
    "                max_length=self.max_text_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "    \n",
    "    def decode(self, token_ids, skip_special_tokens=True):\n",
    "        return self.tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)\n",
    "\n",
    "class xsumDataset(Dataset):\n",
    "    def __init__(self, split=\"train\", max_text_length=512, max_summary_length=128):\n",
    "        self.dataset = load_dataset(\"EdinburghNLP/xsum\", trust_remote_code=True)[split]\n",
    "        self.tokenizer = sumTokenizer(max_text_length, max_summary_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Get text and summary from dataset\n",
    "        text = self.dataset[i][\"document\"]\n",
    "        summary = self.dataset[i][\"summary\"]\n",
    "\n",
    "        # Tokenize input and target\n",
    "        inputs = self.tokenizer(text ,is_target=False)\n",
    "        targets = self.tokenizer(summary, is_target=True)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"input_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"target_ids\": targets[\"input_ids\"].squeeze(0),\n",
    "            \"target_mask\": targets[\"attention_mask\"].squeeze(0)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length=512\n",
    "max_summary_length=128\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "train_set = xsumDataset(split=\"train\", max_text_length=max_text_length, max_summary_length=max_summary_length)\n",
    "val_set = xsumDataset(split=\"validation\", max_text_length=max_text_length, max_summary_length=max_summary_length)\n",
    "test_set = xsumDataset(split=\"test\", max_text_length=max_text_length, max_summary_length=max_summary_length)\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input: Prison Link Cymru had 1,099 referrals in 2015-16 and said some ex-offenders were living rough for up to a year before finding suitable accommodation.\n",
      "Workers at the charity claim investment in housing would be cheaper than jailing homeless repeat offenders.\n",
      "The Welsh Government said more people than ever were getting help to address housing problems.\n",
      "Changes to the Housing Act in Wales, introduced in 2015, removed the right for prison leavers to be given priority for accommodation.\n",
      "Prison Link Cymru, which helps people find accommodation after their release, said things were generally good for women because issues such as children or domestic violence were now considered.\n",
      "However, the same could not be said for men, the charity said, because issues which often affect them, such as post traumatic stress disorder or drug dependency, were often viewed as less of a priority.\n",
      "Andrew Stevens, who works in Welsh prisons trying to secure housing for prison leavers, said the need for accommodation was \"chronic\".\n",
      "\"There's a desperate need for it, finding suitable accommodation for those leaving prison there is just a lack of it everywhere,\" he said.\n",
      "\"It could take six months to a year, without a lot of help they could be on the streets for six months.\n",
      "\"When you think of the consequences of either being on the street, especially with the cold weather at the moment or you may have a roof over your head, sometimes there is only one choice.\"\n",
      "Mr Stevens believes building more one-bedroom flats could help ease the problem.\n",
      "\"The average price is a hundred pounds a week to keep someone in a rented flat, prison is a lot more than that so I would imagine it would save the public purse quite a few pounds,\" he said.\n",
      "Official figures show 830 one-bedroom properties were built in the year to March 2016, of an overall total of 6,900 new properties in Wales.\n",
      "Marc, 50, who has been in and out of prison for the past 20 years for burglary offences, said he struggled to find accommodation each time he was released.\n",
      "He said he would ask himself: \"Where am I going to stay? Where am I going to live? Have I got somewhere where I can see my daughter.\"\n",
      "\"You're put out among the same sort of people doing the same sort of thing, and it's difficult, it's difficult to get away from it. It's like every man for himself, there's nothing.\"\n",
      "Marc has now \n",
      "\n",
      "Test target: There is a \"chronic\" need for more housing for prison leavers in Wales, according to a charity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:497: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output: ['There is a \"desperate need\" for housing for ex-prisoners in Wales, a charity has said.']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = sumTokenizer(max_text_length=max_text_length, max_summary_length=max_summary_length)\n",
    "\n",
    "\n",
    "test_batch = next(iter(test_loader))\n",
    "input_ids = test_batch[\"input_ids\"].to(device) \n",
    "src_mask = test_batch[\"input_mask\"].to(device)\n",
    "target_ids = test_batch[\"target_ids\"].to(device)\n",
    "tgt_mask = test_batch[\"target_mask\"].to(device)\n",
    "\n",
    "print(\"Test input:\", tokenizer.tokenizer.decode(input_ids[0], skip_special_tokens=True), \"\\n\")\n",
    "print(\"Test target:\", tokenizer.tokenizer.decode(target_ids[0], skip_special_tokens=True))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids)\n",
    "\n",
    "predicted_text = tokenizer.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(\"Predicted Output:\", predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 9.7185\n",
      "{'rouge1': 0.4888888888888889, 'rouge2': 0.23255813953488372, 'rougeL': 0.4888888888888889, 'rougeLsum': 0.4888888888888889}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "# Load the ROUGE metric\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "test_loss = 0\n",
    "all_references = []\n",
    "all_hypotheses = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        src_mask = batch[\"input_mask\"].to(device)\n",
    "        target_ids = batch[\"target_ids\"].to(device)\n",
    "        tgt_mask = batch[\"target_mask\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=src_mask,\n",
    "            labels=target_ids,\n",
    "            decoder_attention_mask=tgt_mask\n",
    "        )\n",
    "\n",
    "        # Calculate cross entropy loss directly\n",
    "        loss = outputs.loss\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Convert outputs and targets to strings for ROUGE score\n",
    "        predictions = tokenizer.tokenizer.batch_decode(outputs.logits.argmax(dim=-1), skip_special_tokens=True)\n",
    "        references = tokenizer.tokenizer.batch_decode(target_ids, skip_special_tokens=True)\n",
    "\n",
    "        # Calculate ROUGE scores\n",
    "        results = rouge.compute(predictions=predictions, references=references, tokenizer=lambda x: x.split())\n",
    "        all_references.extend(references)\n",
    "        all_hypotheses.extend(predictions)\n",
    "\n",
    "# Calculate average test loss\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "# Print ROUGE scores\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
